---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: "3"

x-vars: &vars
  TALOS_VERSION:
    sh: yq 'select(document_index == 1).spec.postBuild.substitute.TALOS_VERSION' {{.KUBERNETES_DIR}}/{{.cluster}}/apps/system-upgrade/system-upgrade-controller/ks.yaml
  TALOS_SCHEMATIC_ID:
    sh: yq 'select(document_index == 1).spec.postBuild.substitute.TALOS_SCHEMATIC_ID' {{.KUBERNETES_DIR}}/{{.cluster}}/apps/system-upgrade/system-upgrade-controller/ks.yaml
  KUBERNETES_VERSION:
    sh: yq 'select(document_index == 1).spec.postBuild.substitute.KUBERNETES_VERSION' {{.KUBERNETES_DIR}}/{{.cluster}}/apps/system-upgrade/system-upgrade-controller/ks.yaml
  CONTROLLER:
    sh: talosctl --context {{.cluster}} config info --output json | jq --raw-output '.endpoints[]' | shuf -n 1

tasks:
  apply-config:
    desc: Apply Talos configuration to a node
    cmd: |
      sops --decrypt {{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/config/{{.hostname}}.secret.sops.yaml | \
          $GOPATH/bin/envsubst | \
              talosctl --context {{.cluster}} apply-config --nodes {{.hostname}} --file /dev/stdin --insecure
    env: *vars
    vars:
      mode: '{{.mode | default "no-reboot"}}'
    requires:
      vars: ["cluster", "hostname"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/config/{{.hostname}}.secret.sops.yaml
      #- talosctl --context {{.cluster}} --nodes {{.hostname}} get machineconfig >/dev/null 2>&1

  upgrade:
    desc: Upgrade Talos on a node
    cmds:
      - until kubectl --context {{.cluster}} wait --timeout=5m --for=condition=Complete jobs --all --all-namespaces; do sleep 10; done
      - talosctl --context {{.cluster}} --nodes {{.hostname}} upgrade --image="factory.talos.dev/installer/{{.TALOS_SCHEMATIC_ID}}:{{.TALOS_VERSION}}" --wait=true --timeout=10m --preserve=true
      - talosctl --context {{.cluster}} --nodes {{.hostname}} health --wait-timeout=10m --server=false
      - until kubectl --context {{.cluster}} wait --timeout=5m --for=jsonpath=.status.ceph.health=HEALTH_OK cephcluster --all --all-namespaces; do sleep 10; done
    vars: *vars
    requires:
      vars: ["cluster", "hostname"]
    preconditions:
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.hostname}} get machineconfig >/dev/null 2>&1

  upgrade-k8s:
    desc: Upgrade Kubernetes
    cmds:
      - until kubectl --context {{.cluster}} wait --timeout=5m --for=condition=Complete jobs --all --all-namespaces; do sleep 10; done
      - talosctl --context {{.cluster}} --nodes {{.CONTROLLER}} upgrade-k8s --to {{.KUBERNETES_VERSION}}
    vars: *vars
    requires:
      vars: ["cluster"]
    preconditions:
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.CONTROLLER}} get machineconfig >/dev/null 2>&1

  reset-node:
    desc: Reset a Talos node and shut it down
    prompt: Reset Talos '{{.hostname}}' node on the '{{.cluster}}' cluster ... continue?
    cmd: talosctl --context {{.cluster}} reset --nodes {{.hostname}} --graceful=false
    requires:
      vars: ["cluster", "hostname"]
    preconditions:
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.hostname}} get machineconfig >/dev/null 2>&1

  reset-cluster:
    desc: Reset all the Talos nodes and shut 'em down
    prompt: Reset Talos on the '{{.cluster}}' cluster ... continue?
    cmd: talosctl --context {{.cluster}} reset --nodes {{.nodes}} --graceful=false
    vars:
      nodes:
        sh: talosctl --context {{.cluster}} config info --output json | jq --join-output '[.nodes[]] | join(",")'
    requires:
      vars: ["cluster"]
    preconditions:
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.nodes}} get machineconfig >/dev/null 2>&1

  bootstrap:
    desc: Bootstrap Talos
    summary: |
      Args:
        cluster: Cluster to run command against (required)
    prompt: Bootstrap Talos on the '{{.cluster}}' cluster ... continue?
    cmds:
      - task: bootstrap-etcd
        vars: &vars
          cluster: "{{.cluster}}"
          endpoint: "{{.endpoint}}"
      - task: fetch-kubeconfig
        vars: *vars
      - task: bootstrap-apps
        vars: *vars
    requires:
      vars: ["cluster", "endpoint"]

  bootstrap-etcd:
    desc: Bootstrap Etcd
    cmd: until talosctl --context {{.cluster}} --nodes {{.endpoint}} --endpoints {{.endpoint}} bootstrap; do sleep 10; done
    vars:
      controller:
        sh: talosctl --context {{.cluster}} config info --output json | jq --raw-output '.endpoints[0]'
    requires:
      vars: ["cluster"]
    preconditions:
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1

  bootstrap-apps:
    desc: Bootstrap core apps needed for Talos
    cmd: helmfile --quiet --kube-context {{.cluster}} --file {{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/apps/helmfile.yaml apply --skip-diff-on-install --suppress-diff
    requires:
      vars: ["cluster"]
    preconditions:
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/apps/helmfile.yaml

  fetch-kubeconfig:
    desc: Fetch kubeconfig from Talos controllers
    cmd: |
      talosctl --context {{.cluster}} kubeconfig --nodes {{.controller}} \
          --force --force-context-name {{.cluster}} {{.KUBERNETES_DIR}}/{{.cluster}}
    vars:
      controller:
        sh: talosctl --context {{.cluster}} config info --output json | jq --raw-output '.endpoints[0]'
    requires:
      vars: ["cluster"]
    preconditions:
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
